[model]
name = unified.prefixtuning
use_description = True
concatenate_description = True
# Should be one of (separate, concatenate, none), we use prompt
knowledge_usage = concatenate
freeze_plm = False
freeze_prefix = False
test = True
prefix_use = concat
prefix_len = False

[lr]
lr_async = True
weight_decay_lm= 0.05
weight_decay_prefix= 0.01
prefix_lr = 3e-5
lm_lr = 1e-6

[dataset]
loader_path = ./tasks/macsum_cnndm.py
data_store_path = ./data
upsample_temp = 1

[seq2seq]
constructor = seq2seq_construction.macsum_cnndm

[prefix_tuning]
prefix_sequence_length = 50
mid_dim = 512
prefix_dropout = 0.0

[evaluate]
tool = metrics.rouge.evaluator

[bert]
location = facebook/bart-large-cnn

